DATA_CONFIG:
    DATASET: &dataset_type V2V4RealMultiEgoDataset
    OBJECT_TYPE: &object_type ['TYPE_VEHICLE']
    max_cav: &max_cav 5
    train_dir: '/data1/Datasets/V2V4Real/train'
    validate_dir: '/data1/Datasets/V2V4Real/test'
    preprocessed_gt_traj_dir: 'preprocessed_data/v2v4real/gt_multiego_speedless'
    perception_model_name: &perception_model_name 'point_pillar_v2vnet_multiego'
    preprocessed_pred_traj_dir: 'preprocessed_data/v2v4real/tracking_trajs_point_pillar_v2vnet_multiego'
    cobevt_fused_features_dir: 'preprocessed_data/v2v4real/fused_features_point_pillar_v2vnet_multiego'
    DATASET_CACHE_DIR: 'preprocessed_data/v2v4real'
    PRETRAINED_MOTION_TRANSFORMER: ''

    PAST_FRAMES: 10
    FUTURE_FRAMES: 50

    CONVEX_HULL_THRESHOLD: -1

    SAMPLE_INTERVAL: {
        'train': 5, 
        'test': 1
    }

    ASYNC: sim
    ASYNC_OVERHEAD: 100
    SEED: 20
    LOC_ERR: false
    XYZ_STD: 0.2
    RYP_STD: 0.2
    DATA_SIZE: 1.06 # Mb!!
    TRANSMISSION_SPEED: 27 # Mbps!!
    BACKBONE_DELAY: 10 # ms

    INFO_FILTER_DICT: 
        filter_info_by_object_type: *object_type

    # for map feature encoding
    POINT_SAMPLED_INTERVAL: 1
    NUM_POINTS_EACH_POLYLINE: 20
    VECTOR_BREAK_DIST_THRESH: 1.0

    NUM_OF_SRC_POLYLINES: 768
    CENTER_OFFSET_OF_MAP: &center_offset [30.0, 0]

    fusion:
        core_method: 'IntermediateFusionDatasetMultiEgo' # LateFusionDataset, EarlyFusionDataset, IntermediateFusionDataset supported
        args: []
    
    # preprocess-related
    preprocess:
        # options: BasePreprocessor, VoxelPreprocessor, BevPreprocessor
        core_method: 'SpVoxelPreprocessor'
        args:
            voxel_size: &voxel_size [0.4, 0.4, 4]
            max_points_per_voxel: 32
            max_voxel_train: 32000
            max_voxel_test: 70000
        # lidar range for each individual cav.
        cav_lidar_range: &cav_lidar [-140.8, -38.4, -3, 140.8, 38.4, 1]

    # anchor box related
    postprocess:
        core_method: 'VoxelPostprocessor' # VoxelPostprocessor, BevPostprocessor supported
        anchor_args:
            cav_lidar_range: *cav_lidar
            l: 3.9
            w: 1.6
            h: 1.56
            r: [0, 90]
            feature_stride: 4
            num: &achor_num 2
        target_args:
            pos_threshold: 0.6
            neg_threshold: 0.45
            score_threshold: 0.20
        order: 'hwl' # hwl or lwh
        max_num: 100 # maximum number of objects in a single frame. use this number to make sure different frames has the same dimension in the same batch
        nms_thresh: 0.15



MODEL:
    CONTEXT_ENCODER:
        NAME: MTREncoder
        DATASET_TYPE: *dataset_type
        NUM_OF_ATTN_NEIGHBORS: 16
        NUM_INPUT_ATTR_AGENT: 22
        NUM_INPUT_ATTR_MAP: 9
        
        NUM_CHANNEL_IN_MLP_AGENT: 256
        NUM_CHANNEL_IN_MLP_MAP: 64
        NUM_LAYER_IN_MLP_AGENT: 3
        NUM_LAYER_IN_MLP_MAP: 5
        NUM_LAYER_IN_PRE_MLP_MAP: 3

        D_MODEL: 256
        FEATURE_DIM: 1024
        NUM_ATTN_LAYERS: 6
        NUM_ATTN_HEAD: 8 
        DROPOUT_OF_ATTN: 0.1 

        USE_LOCAL_ATTN: True

    MOTION_DECODER:
        NAME: MTRDecoder
        DATASET_TYPE: *dataset_type
        OBJECT_TYPE: *object_type 
        CENTER_OFFSET_OF_MAP: *center_offset

        NUM_FUTURE_FRAMES: 50
        NUM_MOTION_MODES: 6

        INTENTION_RANDOM_INIT: False
        INTENTION_POINTS_FILE: 'preprocessed_data/v2v4real/v2v4real_cluster_64_center_dict.pkl'

        D_MODEL: 512
        NUM_DECODER_LAYERS: 6 
        NUM_ATTN_HEAD: 8
        MAP_D_MODEL: 256
        DROPOUT_OF_ATTN: 0.1 

        NUM_BASE_MAP_POLYLINES: 256
        NUM_WAYPOINT_MAP_POLYLINES: 128

        LOSS_WEIGHTS: {
            'cls': 1.0,
            'reg': 1.0, 
            'vel': 0.5
        }

        NMS_DIST_THRESH: 2.5

    MOTION_AGGREGATOR:
        NAME: MotionAggregator
        TYPE: 'None' # 'None' or 'MLP' or 'MLPV2' or 'GCN' or 'MOE' or 'MOEV2' or 'Transformer' etc

OPTIMIZATION:
    BATCH_SIZE_PER_GPU: 1
    NUM_EPOCHS: 30

    OPTIMIZER: AdamW
    LR: 0.0001
    WEIGHT_DECAY: 0.01

    SCHEDULER: lambdaLR
    DECAY_STEP_LIST: [22, 24, 26, 28]
    LR_DECAY: 0.5
    LR_CLIP: 0.000001

    GRAD_NORM_CLIP: 1000.0
